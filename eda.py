# -*- coding: utf-8 -*-
"""EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VVFNGFbSlSe8s-wVbsraPOZekaZusnCT

**EDA**
"""

fra20.printSchema()

fra20.summary().show()

from pyspark.sql.functions import isnull, when, count, col

fra20.select([count(when(isnull(c), c)).alias(c) for c in fra20.columns]).show()

from pyspark.mllib.stat import Statistics

# select variables to check correlation

df_features = fra20.select('back_legroom','city_fuel_economy','daysonmarket','dealer_zip','engine_displacement','front_legroom','fuel_tank_volume','height','highway_fuel_economy','horsepower','length','maximum_seating','mileage',
                           'owner_count','seller_rating','torque','wheelbase','width','transmission_id','wheelsystem_id','fueltype_id ','bodytype_id ','enginetype_id','is_newIndex','franchise_dealerIndex')

# create RDD table for correlation calculation
rdd_table = df_features.rdd.map(lambda row: row[0:])

# get the correlation matrix
corr_mat=Statistics.corr(rdd_table, method="pearson")
print(corr_mat)
fra20.corr(col1='highway_fuel_economy', col2='city_fuel_economy', method='pearson')